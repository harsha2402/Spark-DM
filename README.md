# Spark-DM
Apache Spark is an open-source cluster-computing framework. It works on the concept of map reduce but much more efficient compared to it. The package py-spark was installed on Anaconda in order to use Apache Spark in Windows environment. PySpark is the Python API for Spark. 

Key points in the projects were: 
<b>-Data Collection</b></n>
<b>-Data Preprocessing</b></n>
<b>-Feature Engineering</b></n>
<b>-Classification using pyspark.ml Classifiers</b></n>

Various libraries like pandas, numpy, nytimesarticle were used for the dataframe manipulation.  
